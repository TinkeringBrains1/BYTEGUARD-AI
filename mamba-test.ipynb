{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":673436,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":510348,"modelId":525020}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Definitive Installation for PyTorch and Mamba in Colab/Kaggle ---\n# This process ensures full compatibility between the libraries.\n\n# 1. Completely uninstall existing versions to prevent conflicts.\n# The '-y' flag automatically confirms the uninstall.\nprint(\"--- Step 1: Uninstalling existing torch and mamba libraries ---\")\n!pip uninstall -y torch torchvision torchaudio mamba-ssm causal-conv1d\n\n# 2. Install a specific, known-good version of PyTorch compatible with Colab's CUDA drivers.\nprint(\"\\n--- Step 2: Installing a compatible version of PyTorch ---\")\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n\n# 3. Re-install Mamba from source. This will now compile against the new PyTorch version.\nprint(\"\\n--- Step 3: Compiling and installing Mamba from source ---\")\n!git clone https://github.com/state-spaces/mamba /content/mamba\n%cd /content/mamba\n!pip install .\n%cd /content/\nprint(\"DONE!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install mamba-ssm[causal-conv1d] --no-build-isolation\n!pip install triton","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip3 install -q -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- For the FastAPI Server ---\nimport fastapi\nimport uvicorn\nfrom pydantic import BaseModel\n\n# --- For PyTorch and the AI Model ---\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport pickle\nimport numpy as np\nfrom transformers import AutoTokenizer\nfrom faker import Faker\n# --- For Simulation ---\nimport logging\nimport random\nimport string\nimport math\n\n# --- Check Device ---\ndevice = torch.device(\"cpu\")\nprint(f\"Using device: {device}\")\n\n# --- 1. Define the Fed-Mamba-SCL Architecture (Must match training) ---\n# --- 3. The Fed-Mamba-SCL Architecture ---\n\nclass Mamba(nn.Module):\n    def __init__(self, d_model, d_state=16, d_conv=4, expand=2):\n        super().__init__()\n        self.d_model = d_model\n        self.d_state = d_state\n        self.d_conv = d_conv\n        self.expand = expand\n        self.d_inner = int(self.expand * self.d_model)\n        self.dt_rank = math.ceil(self.d_model / 16)\n\n        self.in_proj = nn.Linear(self.d_model, self.d_inner * 2, bias=False)\n        self.conv1d = nn.Conv1d(\n            in_channels=self.d_inner, out_channels=self.d_inner,\n            bias=True, kernel_size=d_conv, groups=self.d_inner, padding=d_conv - 1,\n        )\n        self.x_proj = nn.Linear(self.d_inner, self.dt_rank + self.d_state * 2, bias=False)\n        self.dt_proj = nn.Linear(self.dt_rank, self.d_inner, bias=True)\n\n        A = torch.arange(1, self.d_state + 1, dtype=torch.float32).repeat(self.d_inner, 1)\n        self.A_log = nn.Parameter(torch.log(A))\n        self.D = nn.Parameter(torch.ones(self.d_inner))\n        self.out_proj = nn.Linear(self.d_inner, self.d_model, bias=False)\n\n    def forward(self, x):\n        batch, seq_len, d = x.shape\n        x_and_res = self.in_proj(x)\n        (x_proj, res) = x_and_res.split(split_size=[self.d_inner, self.d_inner], dim=-1)\n\n        x_conv = x_proj.transpose(1, 2)\n        x_conv = self.conv1d(x_conv)[:, :, :seq_len]\n        x_conv = x_conv.transpose(1, 2)\n        x_conv = F.silu(x_conv)\n\n        x_dbl = self.x_proj(x_conv)\n        (delta, B, C) = x_dbl.split(split_size=[self.dt_rank, self.d_state, self.d_state], dim=-1)\n        delta = F.softplus(self.dt_proj(delta))\n        \n        A = -torch.exp(self.A_log.float())\n        y = []\n        h = torch.zeros(batch, self.d_inner, self.d_state, device=x.device)\n        \n        for t in range(seq_len):\n            dt = delta[:, t, :].unsqueeze(-1)\n            b = B[:, t, :].unsqueeze(1)\n            c = C[:, t, :].unsqueeze(1)\n            u = x_conv[:, t, :].unsqueeze(-1)\n            \n            dA = torch.exp(dt * A)\n            dB = dt * b\n            h = dA * h + dB * u\n            y_t = (h * c).sum(dim=-1) + self.D * u.squeeze(-1)\n            y.append(y_t)\n            \n        y = torch.stack(y, dim=1)\n        y = y * F.silu(res)\n        output = self.out_proj(y)\n        return output\n\n\nclass FedMambaSCL(nn.Module):\n    def __init__(self, vocab_size, num_context_features):\n        super().__init__()\n        # Must match your trained model config\n        self.EMBEDDING_DIM = 640 \n        \n        self.embedding = nn.Embedding(vocab_size, self.EMBEDDING_DIM)\n        \n        # Use the CPU-compatible Mamba class defined above\n        self.mamba = Mamba(\n            d_model=self.EMBEDDING_DIM, \n            d_state=64,\n            d_conv=4, \n            expand=4\n        )\n        \n        self.projector = nn.Sequential(\n            nn.Linear(self.EMBEDDING_DIM + num_context_features, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128) \n        )\n        \n        self.classifier = nn.Sequential(\n            nn.Linear(self.EMBEDDING_DIM + num_context_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input_ids, context_features):\n        embedded_seq = self.embedding(input_ids)\n        mamba_output = self.mamba(embedded_seq)\n        sequence_summary = mamba_output[:, -1, :] \n        combined_features = torch.cat((sequence_summary, context_features), dim=1)\n        pred = self.classifier(combined_features)\n        return pred.squeeze(-1)\n\n# Configuration matching the \"Large\" model\nEMBEDDING_DIM = 640\nNUM_CONTEXT_FEATURES = 1\n\n\n# --- 2. Load Resources ---\nMODEL_PATH = \"/kaggle/input/mamba-fed/pytorch/default/1/fed_mamba_scl\" # Update this path to where you uploaded it\nSCALER_PATH = \"/kaggle/input/mamba-fed/pytorch/default/1/fed_mamba_scl/global_scaler.pkl\"          # Update this path\n\ntry:\n    # Load Tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    print(\"Tokenizer loaded.\")\n\n    # Load Scaler\n    with open(SCALER_PATH, 'rb') as f:\n        scaler = pickle.load(f)\n    print(\"Scaler loaded.\")\n\n    # Load Model\n    model = FedMambaSCL(vocab_size=len(tokenizer), num_context_features=NUM_CONTEXT_FEATURES)\n    model.load_state_dict(torch.load(f\"{MODEL_PATH}/model_state_dict.pth\", map_location=device))\n    model.to(device)\n    model.eval()\n    print(\"Fed-Mamba-SCL Model loaded successfully.\")\n    MODEL_READY = True\nexcept Exception as e:\n    print(f\"CRITICAL ERROR LOADING MODEL: {e}\")\n    MODEL_READY = False\n\n# --- 3. The Prediction Logic ---\ndef is_request_malicious(query_text: str, flow_duration_ms: int) -> bool:\n    if not MODEL_READY: return False\n    \n    try:\n        # 1. Preprocess Text\n        inputs = tokenizer(query_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n        input_ids = inputs['input_ids'].to(device)\n        \n        # 2. Preprocess Context (Flow Duration)\n        # Note: Must reshape to (1, 1) for scaler\n        context_val = np.array([[flow_duration_ms]])\n        context_scaled = scaler.transform(context_val)\n        context_tensor = torch.tensor(context_scaled, dtype=torch.float32).to(device)\n        \n        # 3. Inference\n        with torch.no_grad():\n            output_prob = model(input_ids, context_tensor).item()\n            \n        is_attack = output_prob > 0.5\n        logging.info(f\"Analysis: Text='{query_text[:20]}...' | Dur={flow_duration_ms}ms | Score={output_prob:.4f} | Verdict={'MALICIOUS' if is_attack else 'SAFE'}\")\n        return is_attack\n        \n    except Exception as e:\n        logging.error(f\"Inference Error: {e}\")\n        return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:50:58.056453Z","iopub.execute_input":"2025-12-05T14:50:58.057141Z","iopub.status.idle":"2025-12-05T14:50:58.638685Z","shell.execute_reply.started":"2025-12-05T14:50:58.057113Z","shell.execute_reply":"2025-12-05T14:50:58.637988Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nTokenizer loaded.\nScaler loaded.\nFed-Mamba-SCL Model loaded successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# --- Configuration for our database ---\nDB_FILE = \"employees.db\"\nTABLE_NAME = \"employees\"\nNUM_EMPLOYEES = 1000\nimport os\nimport sqlite3\nfrom tqdm.notebook import tqdm  # Best for Kaggle/Jupyter\n\ndef create_synthetic_db():\n    logging.basicConfig(level=logging.INFO, force=True, format='%(asctime)s - %(levelname)s - %(message)s')\n    fake = Faker('en_IN')\n    if os.path.exists(DB_FILE):\n        os.remove(DB_FILE)\n    \n    conn = sqlite3.connect(DB_FILE)\n    cursor = conn.cursor()\n    cursor.execute(f'''\n    CREATE TABLE {TABLE_NAME} (\n        id INTEGER PRIMARY KEY, name TEXT NOT NULL, email TEXT NOT NULL,\n        job_title TEXT, company TEXT, salary INTEGER\n    )\n    ''')\n    \n    employees = []\n    for i in tqdm(range(1, NUM_EMPLOYEES + 1), desc=\"Generating synthetic data\"):\n        employees.append((\n            i, fake.name(), fake.email(), fake.job(), fake.company(),\n            fake.random_int(min=400000, max=2500000)\n        ))\n        \n    cursor.executemany(f\"INSERT INTO {TABLE_NAME} VALUES (?,?,?,?,?,?)\", employees)\n    conn.commit()\n    conn.close()\n    logging.info(f\"Successfully created database '{DB_FILE}' with {NUM_EMPLOYEES} employee records.\")\n\ncreate_synthetic_db()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:51:04.734813Z","iopub.execute_input":"2025-12-05T14:51:04.735109Z","iopub.status.idle":"2025-12-05T14:51:04.851280Z","shell.execute_reply.started":"2025-12-05T14:51:04.735091Z","shell.execute_reply":"2025-12-05T14:51:04.850729Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating synthetic data:   0%|          | 0/1000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e982b8093b478cb4548f02d72f3747"}},"metadata":{}},{"name":"stderr","text":"2025-12-05 14:51:04,848 - INFO - Successfully created database 'employees.db' with 1000 employee records.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from typing import List\n\napp = fastapi.FastAPI(title=\"ByteGraph-Guard Protected API\")\nconn = sqlite3.connect(\"employees.db\", check_same_thread=False)\nconn.row_factory = sqlite3.Row\n\nclass Employee(BaseModel):\n    id: int; name: str; email: str; job_title: str; company: str; salary: int\n    class Config: from_attributes = True\n\nclass SearchResponse(BaseModel):\n    count: int; data: List[Employee]\n\n@app.get(\"/search\", response_model=SearchResponse)\nasync def search_employee(\n    name: str, \n    # We read the simulated duration from a custom header\n    x_flow_duration: int = fastapi.Header(default=5000, alias=\"X-Flow-Duration\") \n):\n    # --- The AI Guard Layer ---\n    if is_request_malicious(name, x_flow_duration):\n        logging.warning(f\"ðŸš« BLOCKED: Malicious payload detected: '{name}'\")\n        raise fastapi.HTTPException(status_code=403, detail=\"ByteGraph-Guard: Request blocked.\")\n\n    # --- Business Logic (Only runs if AI says Safe) ---\n    logging.info(f\"âœ… ALLOWED: searching for '{name}'\")\n    query = \"SELECT * FROM employees WHERE name = ?\"\n    cursor = conn.cursor()\n    cursor.execute(query, (name,))\n    results = cursor.fetchall()\n    employees_found = [Employee.model_validate(row) for row in results]\n    return SearchResponse(count=len(employees_found), data=employees_found)\n\n# Server runner code (threading) stays the same...\nconfig = uvicorn.Config(app, host=\"0.0.0.0\", port=5000, log_level=\"error\")\nserver = uvicorn.Server(config)\nimport threading\nimport asyncio\ndef run_server():\n    asyncio.run(server.serve())\n    \nserver_thread = threading.Thread(target=run_server, daemon=True)\nserver_thread.start()\nprint(\"Server started on port 5000\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:51:08.632364Z","iopub.execute_input":"2025-12-05T14:51:08.633012Z","iopub.status.idle":"2025-12-05T14:51:08.654949Z","shell.execute_reply.started":"2025-12-05T14:51:08.632985Z","shell.execute_reply":"2025-12-05T14:51:08.654036Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_1012/3813743183.py:7: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.12/migration/\n  class Employee(BaseModel):\n","output_type":"stream"},{"name":"stdout","text":"Server started on port 5000\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport pickle\nimport numpy as np\nimport logging\nfrom transformers import AutoTokenizer\n\n# --- 1. FORCE CPU SETTING ---\n# device = torch.device(\"cpu\")\n# print(f\"âš ï¸ FORCING SIMULATION TO DEVICE: {device}\")\n\n# --- 2. The Pure PyTorch Mamba Class (CPU Compatible) ---\n# DO NOT import mamba_ssm. Use this class instead.\n\n# --- 4. Load Resources ---\nMODEL_PATH = \"/kaggle/input/mamba-fed/pytorch/default/1/fed_mamba_scl\"\nSCALER_PATH = \"/kaggle/input/mamba-fed/pytorch/default/1/fed_mamba_scl/global_scaler.pkl\"\n\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    with open(SCALER_PATH, 'rb') as f:\n        scaler = pickle.load(f)\n\n    model = FedMambaSCL(vocab_size=len(tokenizer), num_context_features=1)\n    \n    # CRITICAL: Map location ensures GPU weights are loaded onto CPU\n    model.load_state_dict(torch.load(f\"{MODEL_PATH}/model_state_dict.pth\", map_location=device))\n    \n    model.to(device)\n    model.eval()\n    logging.info(\"SUCCESS: 35M Parameter Fed-Mamba-SCL Model loaded on CPU.\")\n    MODEL_READY = True\nexcept Exception as e:\n    logging.error(f\"CRITICAL ERROR LOADING MODEL: {e}\")\n    MODEL_READY = False\n\n# --- 5. Prediction Logic (Fail Closed) ---\ndef is_request_malicious(query_text: str, flow_duration_ms: int) -> bool:\n    if not MODEL_READY: \n        logging.error(\"Model not ready. Failing CLOSED (Blocking).\")\n        return True # Block if model is broken\n    \n    try:\n        inputs = tokenizer(query_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n        input_ids = inputs['input_ids'].to(device)\n        \n        context_val = np.array([[flow_duration_ms]])\n        context_scaled = scaler.transform(context_val)\n        context_tensor = torch.tensor(context_scaled, dtype=torch.float32).to(device)\n        \n        with torch.no_grad():\n            output_prob = model(input_ids, context_tensor).item()\n            \n        is_attack = output_prob > 0.5\n        \n        # Logging for visibility\n        verdict = \"MALICIOUS\" if is_attack else \"SAFE\"\n        logging.info(f\"Scan: '{query_text[:15]}...' | Dur: {flow_duration_ms}ms | Score: {output_prob:.4f} | Verdict: {verdict}\")\n        \n        return is_attack\n        \n    except Exception as e:\n        logging.error(f\"Inference Error: {e}\")\n        return True # Fail Closed: Block request on error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T14:51:41.761931Z","iopub.execute_input":"2025-12-05T14:51:41.762839Z","iopub.status.idle":"2025-12-05T14:51:42.352181Z","shell.execute_reply.started":"2025-12-05T14:51:41.762776Z","shell.execute_reply":"2025-12-05T14:51:42.351531Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 14:51:42,348 - INFO - SUCCESS: 35M Parameter Fed-Mamba-SCL Model loaded on CPU.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import requests\nimport random\nimport string\nimport time\nimport logging\n\n# --- 1. Simulation Configuration ---\nSQLI_PAYLOADS = {\"Generic\": [\"' OR 1=1 --\", \"' UNION SELECT user, pass FROM users--\", \"1; WAITFOR DELAY '0:0:5'--\"]}\n\nSTEALTHY_PAYLOADS = [\n    \"'admin'--\", \"105-1\", \"' or 1=1 limit 1 --\", \"smith' OR '1'='1\",\n    \"1 AND 1=1\", \"1' and '1'='1\", \"1024-2\", \"' OR '1'='1\",\n    \"1*1\", \"admin' #\", \"' OR 'x'='x\", \"1=1\", \"' OR 1=1--\",\n    \"OR '1'='1'\", \"' or 'x'='x\", \"x' or 1=1--\", \"' OR 1=1 /*\",\n    \"1' OR '1'='1' --\", \"user1' or 1=1 --\", \"OR+%271%27%3D%271\",\n    \"' AND user IS NULL; --\",\n]\n\nSHARED_TEMPLATES = [\n    \"GET /search?q={query}\",\n    \"POST /login {{'user': '{user}', 'pass': 'password123'}}\",\n    \"GET /api/v1/users?id={user_id}\",\n    \"GET /products/details?productID={product_id}\",\n]\n\nUNIQUE_BENIGN_TEMPLATES = [\n    \"GET /products/{category}/{product_id}\",\n    \"POST /api/v1/cart/add {{'item_id': '{item_id}', 'quantity': {quantity}}}\",\n    \"GET /assets/css/main.css\", \"GET /images/products/{image_name}.jpg\",\n    \"POST /profile/update {{'email': '{email}'}}\", \"GET /blog/posts?page={page_num}\",\n]\n\nUNIQUE_MALICIOUS_TEMPLATES = [\n    \"GET /items/show.php?id={payload}\", \"GET /user/profile?user_id={payload}\",\n    \"GET /search.aspx?q={payload}\", \"POST /search {{'keyword': '{payload}'}}\",\n    \"POST /login.php {{'username': '{payload}', 'password': 'password'}}\",\n    \"GET /admin/login?user={payload}\", \"GET /index.php?page={payload}\",\n]\n\ndef get_random_string(length=10):\n    return ''.join(random.choice(string.ascii_letters + string.digits) for _ in range(length))\n\n# --- 2. Request Generators ---\ndef generate_benign_request():\n    if random.random() < 0.5:\n        template = random.choice(SHARED_TEMPLATES)\n    else:\n        template = random.choice(UNIQUE_BENIGN_TEMPLATES)\n        \n    placeholders = {\n        'query': get_random_string(15), 'user': get_random_string(8),\n        'user_id': str(random.randint(100, 9999)), 'product_id': get_random_string(8),\n        'category': random.choice([\"electronics\", \"books\", \"home\"]),\n        'item_id': str(random.randint(1000, 9999)), 'quantity': random.randint(1, 5),\n        'image_name': get_random_string(12), 'email': \"test.user@example.com\",\n        'page_num': random.randint(1, 20)\n    }\n    return template.format(**placeholders)\n\ndef generate_malicious_request():\n    if random.random() < 0.5:\n        template = random.choice(SHARED_TEMPLATES)\n    else:\n        template = random.choice(UNIQUE_MALICIOUS_TEMPLATES)\n    \n    if random.random() < 0.7:\n        payload = random.choice(STEALTHY_PAYLOADS)\n    else:\n        payload = random.choice(SQLI_PAYLOADS[\"Generic\"])\n    \n    placeholders = {\n        'query': payload, 'user': payload, 'user_id': payload, \n        'product_id': payload, 'payload': payload, 'keyword': payload,\n        'username': payload, 'page': payload\n    }\n    return template.format(**placeholders)\n\n# --- 3. The Simulation Loop ---\ndef run_simulation(num_requests=30):\n    print(f\"\\n{'='*60}\")\n    print(f\"ðŸš€ LAUNCHING FED-MAMBA-SCL SECURITY SIMULATION ({num_requests} REQ)\")\n    print(f\"{'='*60}\")\n    \n    server_url = \"http://127.0.0.1:5000/search\"\n    \n    # Metrics\n    total_correct = 0\n    total_requests = 0\n    stats = {\n        \"true_pos\": 0,  # Attacks caught\n        \"false_neg\": 0, # Attacks missed (Danger)\n        \"true_neg\": 0,  # Valid users allowed\n        \"false_pos\": 0  # Valid users blocked (Annoyance)\n    }\n    \n    for i in range(num_requests):\n        # A. Flip a coin: Benign (50%) or Malicious (50%)\n        is_attack = random.random() < 0.5\n        \n        # B. Generate Data & Duration\n        if is_attack:\n            text = generate_malicious_request()\n            # Attacker duration profile (50-8000ms)\n            duration = random.randint(50, 8000)\n            label = \"ATTACK\"\n        else:\n            text = generate_benign_request()\n            # Benign duration profile (4000-90000ms)\n            duration = random.randint(4000, 90000)\n            label = \"NORMAL\"\n            \n        # C. Send to Server\n        try:\n            response = requests.get(\n                server_url, \n                params={'name': text}, \n                headers={'X-Flow-Duration': str(duration)}\n            )\n            \n            # D. Evaluate Response\n            status = response.status_code\n            is_blocked = (status == 403)\n            \n            # Determine correctness\n            if is_attack:\n                if is_blocked:\n                    verdict = \"âœ… BLOCKED (Success)\"\n                    stats[\"true_pos\"] += 1\n                    total_correct += 1\n                else:\n                    verdict = \"âŒ MISSED (Danger!)\"\n                    stats[\"false_neg\"] += 1\n            else:\n                if not is_blocked:\n                    verdict = \"âœ… ALLOWED (Success)\"\n                    stats[\"true_neg\"] += 1\n                    total_correct += 1\n                else:\n                    verdict = \"âš ï¸ FALSE POSITIVE (Annoyance)\"\n                    stats[\"false_pos\"] += 1\n\n            total_requests += 1\n            current_accuracy = (total_correct / total_requests) * 100\n            \n            # Print Log\n            print(f\"[{i+1:02}] {label:<7} | Dur: {duration:<5} | {verdict} | Acc: {current_accuracy:.1f}%\")\n            \n        except Exception as e:\n            print(f\"[{i+1:02}] CRITICAL CONNECTION ERROR: {e}\")\n            \n        time.sleep(0.1) \n\n    # --- Final Score ---\n    accuracy = (total_correct / total_requests) * 100\n    print(f\"\\n{'='*60}\")\n    print(\"SIMULATION RESULTS\")\n    print(f\"Final Accuracy: {accuracy:.2f}%\")\n    print(f\"{'-'*30}\")\n    print(f\"Attacks Caught (Recall):     {stats['true_pos']} / {(stats['true_pos']+stats['false_neg'])}\")\n    print(f\"Benign Allowed (Specificity): {stats['true_neg']} / {(stats['true_neg']+stats['false_pos'])}\")\n    print(f\"False Positives:             {stats['false_pos']}\")\n    print(f\"{'='*60}\")\n\nif __name__ == \"__main__\":\n    run_simulation(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-05T15:05:30.123439Z","iopub.execute_input":"2025-12-05T15:05:30.123772Z","iopub.status.idle":"2025-12-05T15:05:33.501401Z","shell.execute_reply.started":"2025-12-05T15:05:30.123749Z","shell.execute_reply":"2025-12-05T15:05:33.500597Z"}},"outputs":[{"name":"stderr","text":"2025-12-05 15:05:30,215 - INFO - Scan: 'POST /search {'...' | Dur: 3052ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:30,216 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'POST /search {'keyword': '' UNION SELECT user, pass FROM users--'}'\n","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nðŸš€ LAUNCHING FED-MAMBA-SCL SECURITY SIMULATION (20 REQ)\n============================================================\n[01] ATTACK  | Dur: 3052  | âœ… BLOCKED (Success) | Acc: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:30,382 - INFO - Scan: 'GET /api/v1/use...' | Dur: 75488ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:30,382 - INFO - âœ… ALLOWED: searching for 'GET /api/v1/users?id=2642'\n2025-12-05 15:05:30,549 - INFO - Scan: 'GET /index.php?...' | Dur: 5864ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:30,550 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /index.php?page=' OR 1=1 /*'\n","output_type":"stream"},{"name":"stdout","text":"[02] NORMAL  | Dur: 75488 | âœ… ALLOWED (Success) | Acc: 100.0%\n[03] ATTACK  | Dur: 5864  | âœ… BLOCKED (Success) | Acc: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:30,718 - INFO - Scan: 'GET /images/pro...' | Dur: 74818ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:30,719 - INFO - âœ… ALLOWED: searching for 'GET /images/products/HTQwjbSELWYD.jpg'\n2025-12-05 15:05:30,882 - INFO - Scan: 'GET /products/d...' | Dur: 1443ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:30,883 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /products/details?productID=admin' #'\n","output_type":"stream"},{"name":"stdout","text":"[04] NORMAL  | Dur: 74818 | âœ… ALLOWED (Success) | Acc: 100.0%\n[05] ATTACK  | Dur: 1443  | âœ… BLOCKED (Success) | Acc: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:31,048 - INFO - Scan: 'GET /items/show...' | Dur: 2590ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:31,049 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /items/show.php?id=OR+%271%27%3D%271'\n2025-12-05 15:05:31,212 - INFO - Scan: 'GET /api/v1/use...' | Dur: 17579ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:31,213 - INFO - âœ… ALLOWED: searching for 'GET /api/v1/users?id=5552'\n","output_type":"stream"},{"name":"stdout","text":"[06] ATTACK  | Dur: 2590  | âœ… BLOCKED (Success) | Acc: 100.0%\n[07] NORMAL  | Dur: 17579 | âœ… ALLOWED (Success) | Acc: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:31,377 - INFO - Scan: 'GET /user/profi...' | Dur: 6094ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:31,378 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /user/profile?user_id=' OR 1=1 /*'\n2025-12-05 15:05:31,546 - INFO - Scan: 'GET /user/profi...' | Dur: 5666ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:31,547 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /user/profile?user_id=' OR 1=1 /*'\n","output_type":"stream"},{"name":"stdout","text":"[08] ATTACK  | Dur: 6094  | âœ… BLOCKED (Success) | Acc: 100.0%\n[09] ATTACK  | Dur: 5666  | âœ… BLOCKED (Success) | Acc: 100.0%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:31,713 - INFO - Scan: 'POST /profile/u...' | Dur: 48957ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:31,714 - INFO - âœ… ALLOWED: searching for 'POST /profile/update {'email': 'test.user@example.com'}'\n2025-12-05 15:05:31,882 - INFO - Scan: 'GET /search?q=R...' | Dur: 60339ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:31,883 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /search?q=RjZ05mD2LHKv4at'\n","output_type":"stream"},{"name":"stdout","text":"[10] NORMAL  | Dur: 48957 | âœ… ALLOWED (Success) | Acc: 100.0%\n[11] NORMAL  | Dur: 60339 | âš ï¸ FALSE POSITIVE (Annoyance) | Acc: 90.9%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:32,051 - INFO - Scan: 'GET /products/d...' | Dur: 1592ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:32,052 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /products/details?productID=smith' OR '1'='1'\n2025-12-05 15:05:32,219 - INFO - Scan: 'POST /login.php...' | Dur: 3988ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:32,220 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'POST /login.php {'username': '1; WAITFOR DELAY '0:0:5'--', 'password': 'password'}'\n","output_type":"stream"},{"name":"stdout","text":"[12] ATTACK  | Dur: 1592  | âœ… BLOCKED (Success) | Acc: 91.7%\n[13] ATTACK  | Dur: 3988  | âœ… BLOCKED (Success) | Acc: 92.3%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:32,386 - INFO - Scan: 'GET /products/d...' | Dur: 2809ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:32,387 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /products/details?productID=1' OR '1'='1' --'\n2025-12-05 15:05:32,551 - INFO - Scan: 'GET /blog/posts...' | Dur: 18843ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:32,552 - INFO - âœ… ALLOWED: searching for 'GET /blog/posts?page=1'\n","output_type":"stream"},{"name":"stdout","text":"[14] ATTACK  | Dur: 2809  | âœ… BLOCKED (Success) | Acc: 92.9%\n[15] NORMAL  | Dur: 18843 | âœ… ALLOWED (Success) | Acc: 93.3%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:32,720 - INFO - Scan: 'GET /products/d...' | Dur: 2306ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:32,721 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /products/details?productID=' OR 1=1 /*'\n2025-12-05 15:05:32,891 - INFO - Scan: 'GET /assets/css...' | Dur: 51159ms | Score: 0.0000 | Verdict: SAFE\n2025-12-05 15:05:32,892 - INFO - âœ… ALLOWED: searching for 'GET /assets/css/main.css'\n","output_type":"stream"},{"name":"stdout","text":"[16] ATTACK  | Dur: 2306  | âœ… BLOCKED (Success) | Acc: 93.8%\n[17] NORMAL  | Dur: 51159 | âœ… ALLOWED (Success) | Acc: 94.1%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:33,058 - INFO - Scan: 'POST /login {'u...' | Dur: 5940ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:33,059 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'POST /login {'user': 'Bk95Bjt2', 'pass': 'password123'}'\n2025-12-05 15:05:33,223 - INFO - Scan: 'GET /items/show...' | Dur: 6691ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:33,224 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /items/show.php?id=' OR 'x'='x'\n","output_type":"stream"},{"name":"stdout","text":"[18] NORMAL  | Dur: 5940  | âš ï¸ FALSE POSITIVE (Annoyance) | Acc: 88.9%\n[19] ATTACK  | Dur: 6691  | âœ… BLOCKED (Success) | Acc: 89.5%\n","output_type":"stream"},{"name":"stderr","text":"2025-12-05 15:05:33,395 - INFO - Scan: 'GET /search?q=1...' | Dur: 59924ms | Score: 1.0000 | Verdict: MALICIOUS\n2025-12-05 15:05:33,395 - WARNING - ðŸš« BLOCKED: Malicious payload detected: 'GET /search?q=1MIZpnkOJULO3rs'\n","output_type":"stream"},{"name":"stdout","text":"[20] NORMAL  | Dur: 59924 | âš ï¸ FALSE POSITIVE (Annoyance) | Acc: 85.0%\n\n============================================================\nSIMULATION RESULTS\nFinal Accuracy: 85.00%\n------------------------------\nAttacks Caught (Recall):     11 / 11\nBenign Allowed (Specificity): 6 / 9\nFalse Positives:             3\n============================================================\n","output_type":"stream"}],"execution_count":12}]}